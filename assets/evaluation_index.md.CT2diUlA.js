import{_ as a,c as e,o as l,a3 as t}from"./chunks/framework.CGTGJaqa.js";const r="/iOpsBot-doc/assets/1710410147258.BQwhea8u.png",b=JSON.parse('{"title":"大模型评测","description":"","frontmatter":{},"headers":[],"relativePath":"evaluation/index.md","filePath":"evaluation/index.md"}'),i={name:"evaluation/index.md"},o=t('<h1 id="大模型评测" tabindex="-1">大模型评测 <a class="header-anchor" href="#大模型评测" aria-label="Permalink to &quot;大模型评测&quot;">​</a></h1><h2 id="概述" tabindex="-1">概述 <a class="header-anchor" href="#概述" aria-label="Permalink to &quot;概述&quot;">​</a></h2><p>大模型评测是评估大模型性能的重要步骤。本文将介绍如何使用大模型评测工具，以评估大模型的性能和效果。</p><h2 id="工具选择" tabindex="-1">工具选择 <a class="header-anchor" href="#工具选择" aria-label="Permalink to &quot;工具选择&quot;">​</a></h2><p>在选择大模型评测工具时，需要考虑以下几个方面：</p><ul><li>工具的易用性：选择易于使用的工具，可以减少用户的学习成本。</li><li>工具的灵活性：选择支持多种任务和数据类型的工具，可以满足不同类型的评测需求。</li><li>工具的性能：选择性能稳定的工具，可以保证评测结果的准确性和可靠性。</li></ul><p>常见的大模型评测工具包括：</p><ul><li>自动评测工具：自动评测工具可以根据预定义的指标，自动评估大模型的性能和效果。</li><li>手动评测工具：手动评测工具需要人工参与，根据预定义的指标，对大模型的性能和效果进行评估。</li><li>集成评测工具：集成评测工具可以将多个评测工具集成在一起，形成一个完整的评测流程。</li></ul><h2 id="评测对象" tabindex="-1">评测对象 <a class="header-anchor" href="#评测对象" aria-label="Permalink to &quot;评测对象&quot;">​</a></h2><p>本算法库的主要评测对象为语言大模型与多模态大模型。我们以语言大模型为例介绍评测的具体模型类型。</p><ul><li>基座模型：一般是经过海量的文本数据以自监督学习的方式进行训练获得的模型（如 OpenAI 的 GPT-3，Meta 的 LLaMA），往往具有强大的文字续写能力。</li><li>对话模型：一般是在的基座模型的基础上，经过指令微调或人类偏好对齐获得的模型（如 OpenAI 的 ChatGPT、上海人工智能实验室的书生·浦语），能理解人类指令，具有较强的对话能力。</li></ul><h2 id="评测流程" tabindex="-1">评测流程 <a class="header-anchor" href="#评测流程" aria-label="Permalink to &quot;评测流程&quot;">​</a></h2><p>大模型评测的流程包括以下几个步骤：</p><ol><li>数据准备：准备用于评估的大模型数据集。</li><li>模型训练：使用训练数据集训练大模型。</li><li>模型评估：使用评估数据集评估大模型的性能和效果。</li><li>结果分析：分析评估结果，找出大模型需要改进的地方。</li></ol><h2 id="评估指标" tabindex="-1">评估指标 <a class="header-anchor" href="#评估指标" aria-label="Permalink to &quot;评估指标&quot;">​</a></h2><p>在评测阶段，我们一般以数据集本身的特性来选取对应的评估策略，最主要的依据为标准答案的类型，一般以下几种类型：</p><ul><li><strong>选项</strong>：常见于分类任务，判断题以及选择题，目前这类问题的数据集占比最大，有 MMLU, CEval 数据集等等，评估标准一般使用准确率–ACCEvaluator。</li><li><strong>短语</strong>：常见于问答以及阅读理解任务，这类数据集主要包括 CLUE_CMRC, CLUE_DRCD, DROP 数据集等等，评估标准一般使用匹配率–EMEvaluator。</li><li><strong>句子</strong>：常见于翻译以及生成伪代码、命令行任务中，主要包括 Flores, Summscreen, Govrepcrs, Iwdlt2017 数据集等等，评估标准一般使用 BLEU(Bilingual Evaluation Understudy)–BleuEvaluator。</li><li><strong>段落</strong>：常见于文本摘要生成的任务，常用的数据集主要包括 Lcsts, TruthfulQA, Xsum 数据集等等，评估标准一般使用 ROUGE（Recall-Oriented Understudy for Gisting Evaluation）–RougeEvaluator。</li><li><strong>代码</strong>：常见于代码生成的任务，常用的数据集主要包括 Humaneval，MBPP 数据集等等，评估标准一般使用执行通过率以及 pass@k，目前 Opencompass 支持的有 MBPPEvaluator、HumanEvaluator。</li></ul><p>还有一类<strong>打分类型</strong>评测任务没有标准答案，比如评判一个模型的输出是否存在有毒，可以直接使用相关 API 服务进行打分，目前支持的有 ToxicEvaluator，目前有 realtoxicityprompts 数据集使用此评测方式。</p><h2 id="工具架构" tabindex="-1">工具架构 <a class="header-anchor" href="#工具架构" aria-label="Permalink to &quot;工具架构&quot;">​</a></h2><p><img src="'+r+'" alt="1710410147258"></p><h2 id="评测方法" tabindex="-1">评测方法 <a class="header-anchor" href="#评测方法" aria-label="Permalink to &quot;评测方法&quot;">​</a></h2><p>OpenCompass 采取客观评测与主观评测相结合的方法。针对具有确定性答案的能力维度和场景，通过构造丰富完善的评测集，对模型能力进行综合评价。针对体现模型能力的开放式或半开放式的问题、模型安全问题等，采用主客观相结合的评测方式。</p><h3 id="客观评测" tabindex="-1">客观评测 <a class="header-anchor" href="#客观评测" aria-label="Permalink to &quot;客观评测&quot;">​</a></h3><ul><li><p><strong>判别式评测</strong>：该评测方式基于将问题与候选答案组合在一起，计算模型在所有组合上的困惑度（perplexity），并选择困惑度最小的答案作为模型的最终输出。</p></li><li><p><strong>生成式评测</strong>：该评测方式主要用于生成类任务，如语言翻译、程序生成、逻辑分析题等。具体实践时，使用问题作为模型的原始输入，并留白答案区域待模型进行后续补全。我们通常还需要对其输出进行后处理，以保证输出满足数据集的要求。</p></li></ul><h3 id="主观评测" tabindex="-1">主观评测 <a class="header-anchor" href="#主观评测" aria-label="Permalink to &quot;主观评测&quot;">​</a></h3><p>语言表达生动精彩，变化丰富，大量的场景和能力无法凭借客观指标进行评测。针对如模型安全和模型语言能力的评测，以人的主观感受为主的评测更能体现模型的真实能力，并更符合大模型的实际使用场景。</p><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>大模型评测是评估大模型性能和效果的重要步骤。选择合适的大模型评测工具，根据预定义的指标，对大模型进行性能和效果的评估，找出大模型需要改进的地方。</p><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-label="Permalink to &quot;参考资料&quot;">​</a></h2><ul><li><a href="https://opencompass.org.cn/" target="_blank" rel="noreferrer">opencompass</a></li></ul>',30),n=[o];function s(h,u,d,p,c,m){return l(),e("div",null,n)}const f=a(i,[["render",s]]);export{b as __pageData,f as default};
